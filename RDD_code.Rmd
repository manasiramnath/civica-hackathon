---
title: "Seminar 8"
output:
  word_document: default
  html_document: default
date: "2022-12-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
setwd("/Users/manasi/Desktop/POLS0012")
```

```{r}
m <- read.csv(file = "islamic.csv")
library("rdd")
```

# a) Create a treatment variable, islamicwin, that indicates whether or not the Islamic party won the 1994 election
```{r}
m$islamicwin<-ifelse(m$iwm94>=0,1,0)
```

# b) Calculate the difference in means in secondary school completion rates for women between regions where Islamic parties won and lost in 1994. Do you think this is a credible estimate of the causal effect of Islamic party control? Why or why not?

```{r}
mean(m$hischshr1520f[m$islamicwin==1],na.rm=T)-mean(m$hischshr1520f[m$islamicwin==0],na.rm=T)
```

The answer is -0.0258. A naive interpretation of this would be that Islamic party control leads to lower female education rates. But this is not a very credible estimate of the causal effect, due to selection bias. The treated and untreated regions are likely to have very different potential outcomes; they are imbalanced. For example, it is likely that places that strongly support Islamic parties are less supportive of female education to begin with.

# c) Now we’ll start regression discontinuity analysis. First, select optimal bandwidths for testing female high school completion rates using the Imbens-Kalyanaram procedure. Explain what the bandwidth means in this case.

```{r}
band <- IKbandwidth(m$iwm94,m$hischshr1520f)
band
```

This gives a bandwidth of 0.240. It means the optimal bias-variance tradeoff is achieved in this RD analysis by only including regions where the vote share margin for the Islamic Party was in the interval [−0.24, 0.24]

# d) Use your answer to (c) to create a new dataset containing only data within the optimal bandwidth.
```{r}
rdd_est <- m[m$iwm94<band & m$iwm94>-band,]
```

# e) Find the Local Average Treatment Effect of Islamic party control on women’s secondary school education at the threshold, using the dataset you created in (d) and a simple linear regression that includes the treatment and running variable. How credible do you think this result is?
```{r}
summary(lm(hischshr1520f~iwm94 + islamicwin, data = rdd_est))
```

This gives a LATE estimate of 0.033 with a p value of 0.003, indicating that the effect is strongly statistically significant. This result may not be very credible because it requires that the relationship between female education and the running variable is linear and has the same slope on either side of the cutoff. This is a very strong assumption.

# f) Use RD estimation to find the Local Average Treatment Effect of Islamic party control on men’s and women’s secondary school education at the threshold, using local linear regression estimated with the RDestimate function from the rdd package. Interpret the LATE carefully in words. Does the estimate differ from part (e)?

```{r}
rdest <- RDestimate(hischshr1520f~iwm94,cutpoint=0, bw=band, data=m)
summary(rdest)
```

This gives a LATE estimate of 0.0296 with a p value of 0.017, indicating that the effect is clearly significant at the 5% level. This implies that, for regions close to the cutoff, an election win by an Islamic party leads to an increase in the secondary school completion rate for girls of 2.96 percentage points. The estimate is only slightly lower than in (e).

# g) Plot the relationship between the running variable and outcome using local linear regressions. Use your plot to explain why your results do or do not differ strongly between (e) and (f).

```{r}
plot(rdest, range=c(-0.6,0.6))
abline(v=0)
```

The plot in figure 1 indicates that the relationship between Y and X˜ does seem to be quite linear on either side of the cutoff. That explains why (f) and (g) gave similar results: linearity is a reasonable fit to the data here. That will not always be the case, though

# h) Perform placebo tests to check that the relationship between the running variable and outcome is not fundamentally discontinuous, by estimating RD estimates at placebo cutoffs of -0.1, -0.05, 0.05 and 0.1. What do you conclude?
```{r}
summary(RDestimate(hischshr1520f~iwm94, bw = band,cutpoint = -0.1, data=m))
```

statistically significant LATE: if you had plotted a line at -0.1, would have seen such a pattern, and theoretically it shouldn't jump 

```{r}
summary(RDestimate(hischshr1520f~iwm94, bw = band,cutpoint = -0.05, data=m))
```

```{r}
summary(RDestimate(hischshr1520f~iwm94, bw = band,cutpoint = 0.05, data=m))
```

```{r}
summary(RDestimate(hischshr1520f~iwm94, bw = band,cutpoint = 0.1, data=m))

```

At -0.05, 0.05 and 0.1 there is no evidence of a discontinuous relationship (the p-values are very high, indiciating no evidence of an RD “effect” at those placebo cutoffs). However, at -0.1 there is strong evidence of a discontinuity. This constitutes evidence against a true RD effect because it indicates that the discontinuity we measured at 0 could be only one of many discontinuities in the data. 

In other words, the effect at 0 could have arisen due to chance
alone.

# i) Perform a robustness check for local randomisation at the threshold by estimating RD estimates in the same way as (g) for the three background covariates sexr, lop1994 and lareapre. What do you conclude?
```{r}
summary(RDestimate(sexr~iwm94,bw=band, data=m))
summary(RDestimate(lpop1994~iwm94,bw=band, data=m))
summary(RDestimate(lareapre~iwm94,bw=band, data=m))
```

There is no evidence of discontinuities for these any of these variables. They all have small placebo LATE estimates and high p-values. This suggests that, at least based on these observed covariates, there was no sorting around the threshold: local randomisation is likely to hold.

# j) Perform a McCrary test: another way to check for sorting at the theshold. Plot and interpret the results.
```{r}
DCdensity(m$iwm94,verbose=TRUE)
```
The p-value for the resultant test statistic is 0.51, meaning that we cannot reject the null hypothesis of no discontinuous jump in the density of the running variable. Visually, you can also see that there is no strong evidence for this in the plot.

# k) [Challenging Question] Examine the sensitivity of the main RD result to the choice of bandwidth by calculating and plotting RD estimates and their associated 95% confidence intervals for a range of bandwidths from 0.05 to 0.6. To what extent do the results depend on the choice of bandwidth?
```{r}
rdests=rdci.up=rdci.down <- c()
thresholds <- seq(from=0.05,to=0.6,by=0.005)
for(i in 1:length(thresholds)){
rdest <- RDestimate(hischshr1520f~iwm94,bw=thresholds[i], data=m)
rdests[i] <- rdest$est[1]
rdci.up[i] <- rdests[i] + 1.96*rdest$se[1]
rdci.down[i] <- rdests[i] -1.96*rdest$se[1]
}
pdf("thresholds.pdf")
plot(rdests,type="l",
lwd=2,
ylim=c(-0.1,0.1),
xaxt="n",
xlab="Threshold",
ylab="Estimate")
axis(1,
at=c(1,31,51,71,91,111),
labels=c(0.05,0.2,0.3,0.4,0.5,0.6))
abline(h=0)
lines(rdci.up,
lty=3)
lines(rdci.down,
lty=3)
legend("topright",
c("RD Estimate","95% Confidence Interval"),
lty=c(1,3))
dev.off()
```

The plot shows a fairly typical pattern in RD analysis. At very low bandwidths, very little data is used in estimation, making the variance very high. Unsurprisingly therefore, the confidence interval is very wide at low bandwidths: recall that the optimal IK bandwidth is chosen with the twin goals in mind of reducing bias and variance. As the threshold (and therefore the effective sample size) increases, the confidence interval decreases.

The size of the RD estimate does not change much as the bandwidth increases, which is reassuring. We would not want our result to be extremely sensitive to the bandwidth choice.

Its statistical significance does change somewhat as the threshold changes. It is significant at the 95% level for bandwidths between approximately 0.15 and 0.55, becoming statistically indistinguishable from 0 again at higher bandwidths. Again, this is reassuring, because the main result holds across a wide range of bandwidths, and it would not be very defensible in the first place to do RD estimation with a bandwidth as high as 0.55, where we are using data that is very far indeed from the cutoff. 

Overall, if you saw this plot in a published paper you should feel reasurred that the author’s results are not driven primarily by the choice of threshold.
